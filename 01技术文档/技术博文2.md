# 人工智能实训技术博文（2）
## 本篇技术博文记录实训第4周~第5周知识点及工程概要
> 后两周课程着重讲解最终的项目实现，并对人工智能的机器学习、图像识别进行了入门讲解，主要内容包含：
>> 1.opencv的使用与图像处理
>> 2.ui设计与多线程的实现
>> 3.卷积特征的学习原理
>> 4.项目文件的结构与搭建
### 一、图像处理
   1. opencv：
		core：图像的基本表示
		imgproc：图像处理
		imgcodecs：图像解码：图像IO
		videoio：摄像头与视频的IO
   2. 图像的加载与保存
		retval=cv.imread(filename[, flags]) 	
		例子：img = cv2.imread("import.png",cv2.IMREAD_COLOR)
		返回类型：numpy.ndarray

   3. 图像格式
		numpy.ndarray
			|- 数组
			|- 彩色图像是3维数组：(720, 1280, 3) == (height，width，channel/depth)
			|- 深度在opencv：通道 + 通道的基本类型 
			0xFF 00 00 : BGR 而在Qt中使用 RGB888
		构造ndarray就是构造一个图像（不方便）
		【构造数组（通道数只能是1，3，4）】

   4. 使用python的数据来构造ndarray
		补充：解析表达式：
			list = [5 for x in range(5)]
			print(list)
			>>[5, 5, 5, 5, 5]

   5. 图像的基本操作
		支持的图像：bmp/jpg/png/gif/tiff

   6. 下标运算：[]  ： 右：取值， 左：赋值
		1. 整数，整数数组
		2. 切片
			|- 对象表示
				slice(begin, end, step) : [begin, end)
				slice(end) : begin = 0 ,step = 0
			|- 表达式表示
				begin:end:step	begin:end		end:
			例子：
				#表达式方式
				#img[50:100 , 50:100:3 , 0] = 255 #0表示第一个通道
				#img[: , : , 0] = 0     #去蓝
				#img[img > 100] = 0     #全部位置的全部通道像素大于100的，改为0
				#img[img[: , : , 0] > 100] = 0   #全部位置的第一个通道（蓝色元素）大于100，就改为0

## 二、代码与UI结合
   1. UI设计：
		01. 使用qtdesigner设计ui
			x,y；windowTitle；QObject改为Video
			A. 拖拽组件
			B. 设置组件属性：位置大小，标签，以及其他，
			C. 设置组件的名字： Video / lbl_video，text内容
			D. *设置槽函数
			E. *设计信号与槽
		02. 把ui翻译成python
			工具：pyuic5 -o 输出的文件(py文件)   被翻译的ui文件
			#tool.bat
		03. import python模块
		04. 创建ui对象
			self.ui = Ui_Video()
		05. 使用ui对象
			self.ui.setupUi(self)


   2. 摄像头：
		1.多任务实现
			01. 继承QThread
			02. override run函数
			03. 创建摄像头对象
			04. run实现摄像头的视频采集
			05. 启动线程

		2，数据抓取
			self.dev = cv2.VideoCapture(0, cv2.CAP_DSHOW) 	#创建摄像头驱动
			status, frame = self.dev.read()		#抓取信息


   3. 代码和界面的结合：（摄像头功能和显示界面结合）
		使用信号传递图像：
			01. 定义信号（一直为True）	signal_video
			02. 发送信号（run(self)中）	self.signal_video.emit(h,w,c,frame.tobytes())
			03. 定义槽函数		def show_video(self , h , w , c , data)
			04. 绑定信号与槽
			（信号一直为True,一直运行槽函数show_video,一直在Qt界面输出QPixmap）

		在Qt中显示图像：
			Qt中显示图像就用QPixmap
			（QPixmap主要是用于绘图，针对屏幕显示而最佳化设计，QImage主要是为图像I/O、图片访问和像素修改而设计的。
			当图片小的情况下，直接用QPixmap进行加载，画图时无所谓，当图片大的时候如果直接用QPixmap进行加载，会占很大的内存，一般一张几十K的图片，用QPixmap加载进来会放大很多倍，
			所以一般图片大的情况下，用QImage进行加载，然后转乘QPixmap用户绘制）

		图像的处理：
			在bvideo.py的run(self)中进行图像处理

## 三、卷积特征学习
   1. jupyterlab的使用：
	（LaTex语法：https://www.jianshu.com/p/d26c0b3b71ea）
	（show math as -> tex commands）
		01.M键进行 makedown 和 code 的转换
		02. - $$h(x)= \int _{- \infty} ^{\infty} f(\tau) g(x - \tau) \mathrm{d} \tau$$
		\int = 积分；\infty = 无穷；\tau = 涛；、mathrm{d} = 罗马数字d
		03.![输出图片](dd.png)

   2. 离散的卷积公式的理解：（平滑运算 or 滤波运算）
		1.f(i,j)是3*3矩阵，g(x-i,y-j)是一个3*3模块，运算结果是周围的点加权变为一个新的像素点
		2.原图像是21*21，卷积核是3*3，那么新图像是19*19
		3.卷积运算就是在求梯度特征

		图像特征：
			像素的变化：
			Source Image -(Kernel) > Feature Map
			机器学习就是：找到一个Kernel，使我们得到的Feature Map更加容易识别（分类/侦测/分割/跟踪）
				- 多次卷积运算 -> 特征 -> 分类： 卷积神经网络 

   3. 卷积特征学习：（具体理解看代码中的自己加的注释）
		1.指针和数组：指针是程序员自己分配的，在栈区，数组是计算机分配的，在堆区
		2.几个常用的编程技巧（代码中看）
		3.张量（tensor）是多维数组，目的是把向量、矩阵推向更高的维度
			一阶张量可以理解为一个向量，二阶张量可以理解为矩阵，三阶张量可以理解成立方体，
			四阶张量可以理解成立方体组成的一个向量，五阶张量可以理解成立方体组成的矩阵，依次类推。

			图像通常具有三个维度：高度，宽度和颜色深度。虽然灰度图像（比如MNIST数字图像）只有一个颜色通道，因此可以保存在2D张量中，但按照惯例，图像张量始终是3D张量，灰度图像的彩色通道只有一维。
			因此，如果图像大小为256×256 ，那么128张灰度图像组成的批量可以保存在一个形状为（128，256，256，1）的张量中，而128张彩色图像组成的批量则可以保存在一个形状为（128，256，256，3）的张量中。
		4.求导（grad）：
		5.数据集：
			torch的图像格式：NCHW：数量 通道 高度 宽度（img：高 宽 通道）
			*255和/255：*255是张量变图像，/255则相反，
				为了保证精度，经过了运算的图像矩阵的数据类型会从unit8型变成double型。
				如果直接显示，我们会发现显示的是一个白色的图像。
				这是因为对double型是认为在0~1范围内，即大于1时都是显示为白色，而显示uint8型时是0~255范围
		6.lenet5模型：
			（矩阵）Conv2d : 卷积，根据卷积核进行 边-核+1 的图像处理
			max_pool2d : 磁化，降维，将图像进行 a x a 的缩小
			relu : 修正图像（激活函数），inplace : 在原矩阵上改变
			（矩阵）Linear : 全连接，把好多好多的像素特征点集合成几个特征，这些特征对应某个结果都有一个概率，概率最大的就是预测值

		    输出：
			当使用Softmax函数作为输出节点的激活函数的时候，一般使用交叉熵作为损失函数。
				dim(使 某一行 / 某一列 / 某个对应位置 和为1) : 
			argmax的结果是使得f(x)取得最大值的x点集。
				假设有一个函式 f(t)，t 的可能范围是 {0,1,2}，f(t=0) = 10 ; f(t=1) = 20 ; f(t=2) = 7，那分别对应的y如下：
				y = max f(t) = 20
				y= argmax f(t) = 1

   4. 分类器：
		该函数或模型能够把数据库中的数据纪录映射到给定类别中的某一个，从而可以应用于数据预测。
		总之，分类器是数据挖掘中对样本进行分类的方法的统称，包含决策树、逻辑回归、朴素贝叶斯、神经网络等算法。

		影响一个分类器错误率的因素
		　　(1)、训练集的记录数量。
		　　(2)、属性的数目。
		　　(3)、属性中的信息。
		　　(4)、待预测记录的分布。

		评估方法：
		有两种方法可以用于对分类器的错误率进行评估，它们都假定待预测记录和训练集取自同样的样本分布。
		　　(1) 保留方法(Holdout)
		　　(2) 交叉纠错方法(Cross validation)

			分类器中提到的概念：
			        线性回归
			        误差基本服从正态分布
			        逻辑分布代替正态分布，区别：逻辑分布有累积函数
			        最大似然函数：越大越好
			        损失函数：越小越好	交叉熵，梯度下降法
			步骤：
				加载数据集
				定义学习的w， b
				# 循环
				计算预测值
			 	使用交叉熵计算损失值
				求导数（求导只能用float型）
				更新w，b

## 四、项目工程
   1. 一些小知识：
		判定是否支持GPU
        	self.CUDA = torch.cuda.is_available()
		放到GPU的东西:
			模型权重参数
			训练集数据	
			测试集数据
				最后的下标值和概率值还是要返还给CPU
		模型的保存：
			os 目录保存
			#获取模块的安装路径
			current_dir = os.path.dirname(__file__)
			...
			self.mod_file = os.path.join(current_dir,"mods/lenet5.pt")
			(无论安装到哪都能找到这个绝对路径)

   2. YOLO训练
		1.基本的目录结构：
			01.models.py	核心
			02.utils		类和功能函数
			03.cfg/yolov4_ting.cfg	神经网络模型		Netron	
			04.datasets : 制作自己的数据集
			05.weights/yolov4-tiny.pt	初始化权重
			----------------------------------------------
			06.训练：train.py		run_train.bat
			07.测试和验证：test.py	run_train.bat
			08.侦测效果：detect.py	run_detect.bat
		2.定制数据集训练
		3.封装推理模型

		---------------
		
		训练两个模型：人脸模型/垃圾识别模型
		人脸模型：
			1.收集图片
			2.精灵标注助手标注（英文）
			3.json导出
			4.format检查
			5.datasets数据集建立（目录建立）
			|	faces.data
				│   faces.names
				│   train.txt
				│   valid.txt
				│
				└───faces
			    		├───images
			    		│   	└───train
			    		└───labels
			        			└───train
			6.拷贝图像
			7.faces.names	标签中的名
			   faces.data	仿写就行
			   train.txt		程序编写输出有顺序的文本
				
			   cfg:yolo4-tiny.cfg	classes=4 filters=（5 + 类别数）* 3

   3. API封装
		FaceDetector类中要实现的功能：
		1.图片预处理		pre_image
		2.图像侦测(基于训练模型)	yolo4_det
		3.返回有标注的图像		detect_mark
		4.返回标注的名字		get_name

		python setup.py install
		从此，调用库，创建对象，调用函数就能实现识别人脸

   4. 人脸登录的实现：
		1.推理模型已经安装到python,需要时调用库即可
		2.两个窗体：guis中的：garbagehome ,	facelogin
			先展示登录窗体	主窗体一直隐藏
			找路径	help(类)：可以更清楚地理解
		3.qt界面变为py文件：
			在路径下：pyuic5 -o loginui.py login.ui
		4.窗口大小固定：Login.setFixedSize(800, 520)
		5.摄像头采集图像：
			一直采集，直到采集到人脸，bool值 is_ok 才发生变化
			将采集到的信息以信号 signal_face 的形式一直 emit 被窗口处理后显示
			学会：合理地设置变量(全局/局部)；优雅地关闭线程
		    加入人工智能部分：加入数据验证模块(biz->login->user.py

   5.垃圾识别的实现同上：
		1.另外实现抓取图片和业务识别的能力